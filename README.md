# Neural-Network-from-Scratch-NumPy-

This project implements a simple feedforward neural network from scratch using only NumPy, without relying on deep learning frameworks.

ğŸ” Whatâ€™s Included

Forward propagation

Binary Cross-Entropy loss

Backpropagation using chain rule

Gradient Descent optimization

ReLU & Sigmoid activation functions

ğŸ—ï¸ Network Architecture
Input Layer â†’ Hidden Layer (ReLU) â†’ Output Layer (Sigmoid)

ğŸ¯ Goal

To understand how neural networks actually learn by manually implementing every step involved in training.

ğŸš€ Why This Matters

Building a neural network from scratch removes the black box behind deep learning frameworks and strengthens core ML & DL fundamentals.

ğŸ§ª Tools Used

Python

NumPy

ğŸ“Œ Next Step

Extending this implementation using PyTorch and scaling it to deeper networks.

